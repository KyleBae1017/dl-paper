# ðŸ“‘ Deep Learning Papers What I Read / Plan to Read

- Major Interests : GNNs, Generative models, Transformer-based models
- Reading not only papers about interesting topics, also essential papers to understand deep learning techniques and trend

## GNNs
### Basic Graph ML / GNNs
- [ ] node2vec: Scalable Feature Learning for Networks
- [ ] Semi-Supervised Classification with Graph Convolutional Networks (GCN)
- [X] Inductive Representation Learning on Large Graphs (GraphSAGE)
- [ ] Neural Message Passing for Quantum Chemistry (MPNN)
- [ ] Graph Attention Networks (GAT, ICLR 2018)
- [ ] Predict Then Propagate: Graph Neural Networks Meet Personalized PageRank (PPNP/APPNP, ICLR 2019)

### Heterogeneous Graphs
- [ ] metapath2vec: Scalable Representation Learning for Heterogeneous Networks (KDD 2017)
- [ ] Graph Transformer Networks (GTN)

### Heterophily 

## Transformer-based models
- [ ] Attention Is All You Need (Transformer, NeurIPS 2017)
- [Original Paper Link](https://arxiv.org/abs/1706.03762) 
- [ ] End-to-End Object Detection with Transformers (DETR, ECCV 2020)
- [Original Paper Link](https://arxiv.org/abs/2005.12872)
- [ ] MLP-Mixer: An all-MLP Architecture for Vision
